{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "28e6e614-e360-4292-965e-0d255027e9b9"
      },
      "outputs": [],
      "source": [
        "# Copyright 2021 NVIDIA Corporation. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ],
      "id": "28e6e614-e360-4292-965e-0d255027e9b9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b88dc1a-a92d-44cc-9fb7-d9e2ef20c8e2"
      },
      "source": [
        "<img src=\"http://developer.download.nvidia.com/compute/machine-learning/frameworks/nvidia_logo.png\" style=\"width: 90px; float: right;\">\n",
        "\n",
        "# Accelerating HuggingFace T5 Inference with TensorRT\n",
        "\n",
        "T5 is an encoder-decoder model that converts all NLP problems into a text-to-text format. More specifically, it does so by encoding  different tasks as text directives in the input stream. This enables a single model to be trained supervised on a wide variety of NLP tasks such as translation, classification, Q&A and summarization.\n",
        "\n",
        "This notebook shows 3 easy steps to convert a [HuggingFace PyTorch T5 model](https://huggingface.co/transformers/model_doc/t5.html) to a TensorRT engine for high-performance inference.\n",
        "\n",
        "1. [Download HuggingFace T5 model](#1)\n",
        "1. [Convert to ONNX format](#2)\n",
        "1. [Convert to TensorRT engine](#3)\n",
        "\n",
        "## Prerequisite\n",
        "\n",
        "Follow the instruction at https://github.com/NVIDIA/TensorRT to build the TensorRT-OSS docker container required to run this notebook.\n",
        "\n",
        "Next, we install some extra dependencies, then restart the kernel."
      ],
      "id": "9b88dc1a-a92d-44cc-9fb7-d9e2ef20c8e2"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WcYGu6p4U4_j"
      },
      "outputs": [],
      "source": [
        "!tar -xf T5.tar.gz\n",
        "!tar -xf NNDF.tar.gz\n",
        "!tar -xf Polygraphy.tar.gz\n"
      ],
      "id": "WcYGu6p4U4_j"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0c36ecb7-c622-4d95-a851-b9a6eb18e81b"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip3 install -r ../requirements.txt\n",
        "\n",
        "import IPython\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ],
      "id": "0c36ecb7-c622-4d95-a851-b9a6eb18e81b"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7kteScKaSpPP"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ],
      "id": "7kteScKaSpPP"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ax4szGB7NqoX",
        "outputId": "18db5c45-ae9c-46b5-ec56-317fedd1bf3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorrt in /usr/local/lib/python3.10/dist-packages (8.6.1)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch-tensorrt in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
            "Requirement already satisfied: torch<2.1,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from torch-tensorrt) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch-tensorrt) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch-tensorrt) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch-tensorrt) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch-tensorrt) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch-tensorrt) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch-tensorrt) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<2.1,>=2.0.1->torch-tensorrt) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<2.1,>=2.0.1->torch-tensorrt) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<2.1,>=2.0.1->torch-tensorrt) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<2.1,>=2.0.1->torch-tensorrt) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: T5 in /usr/local/lib/python3.10/dist-packages (0.9.4)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from T5) (1.4.0)\n",
            "Requirement already satisfied: babel in /usr/local/lib/python3.10/dist-packages (from T5) (2.12.1)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.10/dist-packages (from T5) (0.6.2)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.10/dist-packages (from T5) (2.2.4)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from T5) (0.5.0)\n",
            "Requirement already satisfied: mesh-tensorflow[transformer]>=0.1.13 in /usr/local/lib/python3.10/dist-packages (from T5) (0.1.21)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from T5) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from T5) (1.22.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from T5) (1.5.3)\n",
            "Requirement already satisfied: rouge-score>=0.1.2 in /usr/local/lib/python3.10/dist-packages (from T5) (0.1.2)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.10/dist-packages (from T5) (2.3.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from T5) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from T5) (1.10.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from T5) (0.1.99)\n",
            "Requirement already satisfied: seqio-nightly in /usr/local/lib/python3.10/dist-packages (from T5) (0.0.15.dev20230621)\n",
            "Requirement already satisfied: six>=1.14 in /usr/local/lib/python3.10/dist-packages (from T5) (1.16.0)\n",
            "Requirement already satisfied: tfds-nightly in /usr/local/lib/python3.10/dist-packages (from T5) (4.9.2.dev202306210051)\n",
            "Requirement already satisfied: transformers>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from T5) (4.30.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from mesh-tensorflow[transformer]>=0.1.13->T5) (0.18.3)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from mesh-tensorflow[transformer]>=0.1.13->T5) (4.9.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=2.7.0->T5) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.7.0->T5) (0.15.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.7.0->T5) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.7.0->T5) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.7.0->T5) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=2.7.0->T5) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.7.0->T5) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.7.0->T5) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.7.0->T5) (4.65.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->T5) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->T5) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->T5) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->T5) (2022.7.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu->T5) (2.7.0)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->T5) (0.8.10)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu->T5) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu->T5) (4.9.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->T5) (3.1.0)\n",
            "Requirement already satisfied: clu in /usr/local/lib/python3.10/dist-packages (from seqio-nightly->T5) (0.0.9)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from seqio-nightly->T5) (0.4.10)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from seqio-nightly->T5) (0.4.10+cuda11.cudnn86)\n",
            "Requirement already satisfied: pyglove in /usr/local/lib/python3.10/dist-packages (from seqio-nightly->T5) (0.3.0)\n",
            "Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.10/dist-packages (from seqio-nightly->T5) (2.12.1)\n",
            "Requirement already satisfied: protobuf<=3.20.3 in /usr/local/lib/python3.10/dist-packages (from seqio-nightly->T5) (3.20.3)\n",
            "Requirement already satisfied: array-record in /usr/local/lib/python3.10/dist-packages (from tfds-nightly->T5) (0.2.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tfds-nightly->T5) (0.1.8)\n",
            "Requirement already satisfied: etils[enp,epath,etree]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tfds-nightly->T5) (1.2.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tfds-nightly->T5) (2.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tfds-nightly->T5) (5.9.5)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tfds-nightly->T5) (1.13.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from tfds-nightly->T5) (2.3.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tfds-nightly->T5) (0.10.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from tfds-nightly->T5) (1.14.1)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tfds-nightly->T5) (5.12.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tfds-nightly->T5) (4.5.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tfds-nightly->T5) (3.15.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers>=2.7.0->T5) (2023.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=2.7.0->T5) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=2.7.0->T5) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=2.7.0->T5) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=2.7.0->T5) (3.4)\n",
            "Requirement already satisfied: flax in /usr/local/lib/python3.10/dist-packages (from clu->seqio-nightly->T5) (0.6.9)\n",
            "Requirement already satisfied: ml-collections in /usr/local/lib/python3.10/dist-packages (from clu->seqio-nightly->T5) (0.1.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax->seqio-nightly->T5) (0.1.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->seqio-nightly->T5) (3.3.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata->tfds-nightly->T5) (1.59.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text->seqio-nightly->T5) (0.13.0)\n",
            "Requirement already satisfied: tensorflow<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text->seqio-nightly->T5) (2.12.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->seqio-nightly->T5) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->seqio-nightly->T5) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->seqio-nightly->T5) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->seqio-nightly->T5) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->seqio-nightly->T5) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->seqio-nightly->T5) (3.8.0)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->seqio-nightly->T5) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->seqio-nightly->T5) (16.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->seqio-nightly->T5) (67.7.2)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->seqio-nightly->T5) (2.12.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->seqio-nightly->T5) (2.12.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->seqio-nightly->T5) (0.32.0)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax->clu->seqio-nightly->T5) (1.0.5)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (from flax->clu->seqio-nightly->T5) (0.1.5)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.10/dist-packages (from flax->clu->seqio-nightly->T5) (0.2.1)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax->clu->seqio-nightly->T5) (0.1.36)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.10/dist-packages (from flax->clu->seqio-nightly->T5) (13.3.4)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.10/dist-packages (from ml-collections->clu->seqio-nightly->T5) (0.6.0.post1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.13,>=2.12.0->tensorflow-text->seqio-nightly->T5) (0.40.0)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax->clu->seqio-nightly->T5) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax->clu->seqio-nightly->T5) (2.14.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->seqio-nightly->T5) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->seqio-nightly->T5) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->seqio-nightly->T5) (3.4.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->seqio-nightly->T5) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->seqio-nightly->T5) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->seqio-nightly->T5) (2.3.0)\n",
            "Requirement already satisfied: chex>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from optax->flax->clu->seqio-nightly->T5) (0.1.7)\n",
            "Requirement already satisfied: cached_property in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->clu->seqio-nightly->T5) (1.5.2)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->clu->seqio-nightly->T5) (1.5.6)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.5->optax->flax->clu->seqio-nightly->T5) (0.12.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->seqio-nightly->T5) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->seqio-nightly->T5) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->seqio-nightly->T5) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->seqio-nightly->T5) (1.3.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=11.1->flax->clu->seqio-nightly->T5) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->seqio-nightly->T5) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->seqio-nightly->T5) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->seqio-nightly->T5) (3.2.2)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!python3 -m pip install --upgrade tensorrt\n",
        "!pip install torch-tensorrt\n",
        "!pip install T5"
      ],
      "id": "ax4szGB7NqoX"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXv9Kg3wOX5I",
        "outputId": "0b25dc6d-354f-4d53-ccb9-10063fe4ffae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: SentencePiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install SentencePiece\n",
        "!pip install accelerate"
      ],
      "id": "AXv9Kg3wOX5I"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "235d2f1b-439e-4cd0-8286-1d63a13f2cf3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "ROOT_DIR = os.path.abspath(\"../\")\n",
        "sys.path.append(ROOT_DIR)\n",
        "\n",
        "import torch\n",
        "import tensorrt as trt\n",
        "\n",
        "# huggingface\n",
        "from transformers import (\n",
        "    T5ForConditionalGeneration,\n",
        "    T5Tokenizer,\n",
        "    T5Config,\n",
        ")"
      ],
      "id": "235d2f1b-439e-4cd0-8286-1d63a13f2cf3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af4254e2-11fd-4bc7-ac0b-60b1a9e07c4e"
      },
      "source": [
        "<a id=\"1\"></a>\n",
        "\n",
        "## 1. Download HuggingFace T5 model\n",
        "\n",
        "First, we download the original HuggingFace PyTorch T5 model from HuggingFace model hubs, together with its associated tokernizer.\n",
        "\n",
        "The T5 variants  that are suported by TensorRT 8 are:  t5-small (60M), t5-base (220M), t5-large (770M)"
      ],
      "id": "af4254e2-11fd-4bc7-ac0b-60b1a9e07c4e"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fae66d58-f994-4987-8f1d-1fa8ac2ec8b4"
      },
      "outputs": [],
      "source": [
        "T5_VARIANT = 'google/flan-t5-large' # choices: t5-small | t5-base | t5-large\n",
        "\n",
        "t5_model = T5ForConditionalGeneration.from_pretrained(T5_VARIANT)\n",
        "tokenizer = T5Tokenizer.from_pretrained(T5_VARIANT)\n",
        "config = T5Config(T5_VARIANT)"
      ],
      "id": "fae66d58-f994-4987-8f1d-1fa8ac2ec8b4"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7252ca90-1104-40dc-8e72-f51c07a4cd11",
        "outputId": "8d651665-56b1-417d-9aca-dc75a2dfce96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pytorch Model saved to ./models/google/flan-t5-large/pytorch\n"
          ]
        }
      ],
      "source": [
        "# save model locally\n",
        "pytorch_model_dir = './models/{}/pytorch'.format(T5_VARIANT)\n",
        "!mkdir -p $pytorch_model_dir\n",
        "\n",
        "t5_model.save_pretrained(pytorch_model_dir)\n",
        "print(\"Pytorch Model saved to {}\".format(pytorch_model_dir))"
      ],
      "id": "7252ca90-1104-40dc-8e72-f51c07a4cd11"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11ea023d-c4d4-43bb-9d77-c76684e0b06f"
      },
      "source": [
        "### Inference with PyTorch model\n",
        "\n",
        "Next, we will carry out inference with the PyTorch model.\n",
        "\n",
        "#### Single example inference"
      ],
      "id": "11ea023d-c4d4-43bb-9d77-c76684e0b06f"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bc45d9bc-b6ef-485e-8832-6628c292e315"
      },
      "outputs": [],
      "source": [
        "inputs = tokenizer(\"translate English to German: That is good.\", return_tensors=\"pt\")\n",
        "\n",
        "# inference on a single example\n",
        "t5_model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = t5_model(**inputs, labels=inputs[\"input_ids\"])\n",
        "\n",
        "logits = outputs.logits"
      ],
      "id": "bc45d9bc-b6ef-485e-8832-6628c292e315"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98f7fd8b-2ee3-4d25-9204-7713eb7e90b3",
        "outputId": "ac320c26-3067-402c-e219-760f00d9044f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1353: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Das ist gut.\n"
          ]
        }
      ],
      "source": [
        "# Generate sequence for an input\n",
        "outputs = t5_model.to('cuda:0').generate(inputs.input_ids.to('cuda:0'))\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ],
      "id": "98f7fd8b-2ee3-4d25-9204-7713eb7e90b3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "667fcacc-02cb-415d-a9ff-2d2ec44ef225"
      },
      "source": [
        "#### Model inference benchmark: encoder and decoder stacks\n",
        "\n",
        "For benchmarking purposes, we will employ a helper functions `encoder_inference` and `decoder_inference` which execute the inference repeatedly for the T5 encoder and decoder stacks separately, and measure end to end execution time. Let's take note of this execution time for comparison with TensorRT.\n",
        "\n",
        "`TimingProfile` is a named tuple that specifies the number of experiments and number of times to call the function per iteration (and number of warm-up calls although it is not used here)."
      ],
      "id": "667fcacc-02cb-415d-a9ff-2d2ec44ef225"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgBhGEMhUSp8",
        "outputId": "354575f5-a916-4306-9492-fc250e25a224"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx) (1.22.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx) (4.5.0)\n",
            "Installing collected packages: onnx\n",
            "Successfully installed onnx-1.14.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting nvidia-pyindex\n",
            "  Downloading nvidia-pyindex-1.0.9.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: nvidia-pyindex\n",
            "  Building wheel for nvidia-pyindex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvidia-pyindex: filename=nvidia_pyindex-1.0.9-py3-none-any.whl size=8418 sha256=9aec991ae3d89e9209d10c0c985fa1dbf2dfdce37706a9c214d8bd1f930d90d0\n",
            "  Stored in directory: /root/.cache/pip/wheels/2c/af/d0/7a12f82cab69f65d51107f48bcd6179e29b9a69a90546332b3\n",
            "Successfully built nvidia-pyindex\n",
            "Installing collected packages: nvidia-pyindex\n",
            "Successfully installed nvidia-pyindex-1.0.9\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://pypi.ngc.nvidia.com\n",
            "Collecting onnx-graphsurgeon\n",
            "  Downloading https://developer.download.nvidia.com/compute/redist/onnx-graphsurgeon/onnx_graphsurgeon-0.3.27-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx-graphsurgeon) (1.22.4)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (from onnx-graphsurgeon) (1.14.0)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx->onnx-graphsurgeon) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx->onnx-graphsurgeon) (4.5.0)\n",
            "Installing collected packages: onnx-graphsurgeon\n",
            "Successfully installed onnx-graphsurgeon-0.3.27\n"
          ]
        }
      ],
      "source": [
        "!pip install onnx\n",
        "!pip install nvidia-pyindex\n",
        "!pip install onnx-graphsurgeon"
      ],
      "id": "GgBhGEMhUSp8"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mk9cjaeUTU2W",
        "outputId": "de74139c-e52a-4fa9-c69f-aa3f04a982bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: t5\n",
            "Version: 0.9.4\n",
            "Summary: Text-to-text transfer transformer\n",
            "Home-page: http://github.com/google-research/text-to-text-transfer-transformer\n",
            "Author: Google Inc.\n",
            "Author-email: no-reply@google.com\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: absl-py, babel, editdistance, gin-config, immutabledict, mesh-tensorflow, nltk, numpy, pandas, rouge-score, sacrebleu, scikit-learn, scipy, sentencepiece, seqio-nightly, six, tfds-nightly, transformers\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "!pip show t5"
      ],
      "id": "mk9cjaeUTU2W"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "596ea542-d9e5-4367-b643-d60027fa05e6",
        "outputId": "f909a4dc-3cf4-4b38-990f-a4e7d947c991"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from T5.measurements import decoder_inference, encoder_inference, full_inference\n",
        "from T5.export import T5EncoderTorchFile, T5DecoderTorchFile\n",
        "from NNDF.networks import TimingProfile\n",
        "\n",
        "t5_torch_encoder = T5EncoderTorchFile.TorchModule(t5_model.encoder)\n",
        "t5_torch_decoder = T5DecoderTorchFile.TorchModule(\n",
        "    t5_model.decoder, t5_model.lm_head, t5_model.config\n",
        ")"
      ],
      "id": "596ea542-d9e5-4367-b643-d60027fa05e6"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be755fbc-c53e-4f8d-a9c2-4817167cf93a",
        "outputId": "38fe4a58-0927-47ec-d5a7-1024b1e99f9a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.02550941099980264"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "input_ids = inputs.input_ids\n",
        "\n",
        "encoder_last_hidden_state, encoder_e2e_median_time = encoder_inference(\n",
        "    t5_torch_encoder, input_ids, TimingProfile(iterations=10, number=1, warmup=1,duration=60,percentile=1)\n",
        ")\n",
        "encoder_e2e_median_time"
      ],
      "id": "be755fbc-c53e-4f8d-a9c2-4817167cf93a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "960f05fc-f572-4832-ad82-8a75823866b1"
      },
      "outputs": [],
      "source": [
        "_, decoder_e2e_median_time = decoder_inference(\n",
        "    t5_torch_decoder, input_ids, encoder_last_hidden_state, TimingProfile(iterations=10, number=1, warmup=1,duration=60,percentile=1)\n",
        ")\n",
        "decoder_e2e_median_time"
      ],
      "id": "960f05fc-f572-4832-ad82-8a75823866b1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a99d5a06-a8f5-4ce7-a34c-bc42f07ac706"
      },
      "source": [
        "#### Full model inference and benchmark\n",
        "\n",
        "Next, we will try the T5 model for the task of translation from English to German.\n",
        "\n",
        "For benchmarking purposes, we will employ a helper function `full_inference_greedy` which executes the inference repeatedly and measures end to end execution time. Let's take note of this execution time for comparison with TensorRT."
      ],
      "id": "a99d5a06-a8f5-4ce7-a34c-bc42f07ac706"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pnvTt5YadTfN"
      },
      "outputs": [],
      "source": [
        "pip uninstall transformers"
      ],
      "id": "pnvTt5YadTfN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnZzGL_VdL6D"
      },
      "outputs": [],
      "source": [
        "!pip install transformers==4.10.0"
      ],
      "id": "lnZzGL_VdL6D"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39d511cf-d963-4629-be54-22e9a258716d"
      },
      "outputs": [],
      "source": [
        "from T5.T5ModelConfig import T5ModelTRTConfig\n",
        "\n",
        "decoder_output_greedy, full_e2e_median_runtime = full_inference(\n",
        "    t5_torch_encoder,\n",
        "    t5_torch_decoder,\n",
        "    input_ids,\n",
        "    tokenizer,\n",
        "    TimingProfile(iterations=10, number=1, warmup=1,duration=60,percentile=1),\n",
        "    max_length=T5ModelTRTConfig.MAX_SEQUENCE_LENGTH[\"t5-large\"],\n",
        ")\n",
        "full_e2e_median_runtime"
      ],
      "id": "39d511cf-d963-4629-be54-22e9a258716d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cff48fc-b792-4852-b638-6e2c54099cb2"
      },
      "source": [
        "Let us decode the model's output back into text."
      ],
      "id": "8cff48fc-b792-4852-b638-6e2c54099cb2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "839bc6bc-65dc-499d-ac26-81456dbc1748"
      },
      "outputs": [],
      "source": [
        "# De-tokenize output to raw text\n",
        "print(tokenizer.decode(decoder_output_greedy[0], skip_special_tokens=True))"
      ],
      "id": "839bc6bc-65dc-499d-ac26-81456dbc1748"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d662701-e430-4fdc-ad46-1f296defcf8f"
      },
      "source": [
        "<a id=\"2\"></a>\n",
        "\n",
        "## 2. Convert to ONNX\n",
        "\n",
        "Prior to converting the model to a TensorRT engine, we will first convert the PyTorch model to an intermediate universal format.\n",
        "\n",
        "ONNX is an open format for machine learning and deep learning models. It allows you to convert deep learning and machine learning models from different frameworks such as TensorFlow, PyTorch, MATLAB, Caffe, and Keras to a single format.\n",
        "\n",
        "The steps to convert a PyTorch model to TensorRT are as follows:\n",
        "- Convert the pretrained image segmentation PyTorch model into ONNX.\n",
        "- Import the ONNX model into TensorRT.\n",
        "- Apply optimizations and generate an engine.\n",
        "- Perform inference on the GPU.\n",
        "\n",
        "For the T5 model, we will convert the encoder and decoder seperately."
      ],
      "id": "0d662701-e430-4fdc-ad46-1f296defcf8f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2b2be1a-021c-4f6c-957d-2ff7d1b95976"
      },
      "outputs": [],
      "source": [
        "# helpers\n",
        "from NNDF.networks import NetworkMetadata, Precision"
      ],
      "id": "c2b2be1a-021c-4f6c-957d-2ff7d1b95976"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c50346f7-6c2c-4e4b-ba70-875688947b75"
      },
      "outputs": [],
      "source": [
        "onnx_model_path = './models/{}/ONNX'.format(T5_VARIANT)\n",
        "!mkdir -p $onnx_model_path\n",
        "\n",
        "metadata=NetworkMetadata(T5_VARIANT, Precision('fp16'), None)\n",
        "\n",
        "encoder_onnx_model_fpath = T5_VARIANT + \"-encoder.onnx\"\n",
        "decoder_onnx_model_fpath = T5_VARIANT + \"-decoder-with-lm-head.onnx\"\n",
        "\n",
        "t5_encoder = T5EncoderTorchFile(t5_model.to('cpu'), metadata)\n",
        "t5_decoder = T5DecoderTorchFile(t5_model.to('cpu'), metadata)\n",
        "\n",
        "onnx_t5_encoder = t5_encoder.as_onnx_model(\n",
        "    os.path.join(onnx_model_path, encoder_onnx_model_fpath), force_overwrite=False\n",
        ")\n",
        "onnx_t5_decoder = t5_decoder.as_onnx_model(\n",
        "    os.path.join(onnx_model_path, decoder_onnx_model_fpath), force_overwrite=False\n",
        ")"
      ],
      "id": "c50346f7-6c2c-4e4b-ba70-875688947b75"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7baf007e-5508-485c-a87f-9bfe16260452"
      },
      "source": [
        "<a id=\"3\"></a>\n",
        "\n",
        "## 3. Convert to TensorRT\n",
        "\n",
        "Now we are ready to parse the ONNX encoder and decoder models and convert them to optimized TensorRT engines."
      ],
      "id": "7baf007e-5508-485c-a87f-9bfe16260452"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "037ac958-2627-439c-9db5-27640e3f7967"
      },
      "outputs": [],
      "source": [
        "from T5.export import T5DecoderONNXFile, T5EncoderONNXFile"
      ],
      "id": "037ac958-2627-439c-9db5-27640e3f7967"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bd6e3fc-6797-46b0-a211-ce42d3769105"
      },
      "outputs": [],
      "source": [
        "tensorrt_model_path = './models/{}/tensorrt'.format(T5_VARIANT)\n",
        "!mkdir -p tensorrt_model_path"
      ],
      "id": "6bd6e3fc-6797-46b0-a211-ce42d3769105"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfb64120-9012-40c8-b1e2-4a6366b71294"
      },
      "outputs": [],
      "source": [
        "t5_trt_encoder_engine = T5EncoderONNXFile(\n",
        "                os.path.join(onnx_model_path, encoder_onnx_model_fpath), metadata\n",
        "            ).as_trt_engine(os.path.join(tensorrt_model_path, encoder_onnx_model_fpath) + \".engine\")\n",
        "\n",
        "t5_trt_decoder_engine = T5DecoderONNXFile(\n",
        "                os.path.join(onnx_model_path, decoder_onnx_model_fpath), metadata\n",
        "            ).as_trt_engine(os.path.join(tensorrt_model_path, decoder_onnx_model_fpath) + \".engine\")"
      ],
      "id": "cfb64120-9012-40c8-b1e2-4a6366b71294"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74f7f6fc-1e6a-4ddc-8e9b-543d9e8dab4d"
      },
      "source": [
        "### Inference with TensorRT engine\n",
        "\n",
        "Great, if you have reached this stage, it means we now have an optimized TensorRT engine for the T5 model, ready for us to carry out inference.\n",
        "\n",
        "#### Single example inference\n",
        "The T5 model with TensorRT backend can now be employed in place of the original HuggingFace T5 model.\n"
      ],
      "id": "74f7f6fc-1e6a-4ddc-8e9b-543d9e8dab4d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3954f2f4-c393-463b-a44b-3e5335032b57"
      },
      "outputs": [],
      "source": [
        "# Initialize TensorRT engines\n",
        "from T5.trt import T5TRTEncoder, T5TRTDecoder\n",
        "\n",
        "tfm_config = T5Config(\n",
        "    use_cache=True,\n",
        "    num_layers=T5ModelTRTConfig.NUMBER_OF_LAYERS[T5_VARIANT],\n",
        ")\n",
        "\n",
        "t5_trt_encoder = T5TRTEncoder(\n",
        "                t5_trt_encoder_engine, metadata, tfm_config\n",
        "            )\n",
        "t5_trt_decoder = T5TRTDecoder(\n",
        "                t5_trt_decoder_engine, metadata, tfm_config\n",
        "            )"
      ],
      "id": "3954f2f4-c393-463b-a44b-3e5335032b57"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9544ecb-2671-4b53-a544-08f13424cefe"
      },
      "outputs": [],
      "source": [
        "# Inference on a single sample\n",
        "encoder_last_hidden_state = t5_trt_encoder(input_ids=input_ids)\n",
        "outputs = t5_trt_decoder(input_ids, encoder_last_hidden_state)"
      ],
      "id": "a9544ecb-2671-4b53-a544-08f13424cefe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8d71a327-546f-4b5b-bd42-caaffcceafc7"
      },
      "outputs": [],
      "source": [
        "# Generate sequence for an input\n",
        "from transformers.generation_stopping_criteria import (\n",
        "    MaxLengthCriteria,\n",
        "    StoppingCriteriaList,\n",
        ")\n",
        "\n",
        "max_length = 64\n",
        "\n",
        "decoder_input_ids = torch.full(\n",
        "    (1, 1), tokenizer.convert_tokens_to_ids(tokenizer.pad_token), dtype=torch.int32\n",
        ")\n",
        "encoder_last_hidden_state = t5_trt_encoder(input_ids=input_ids)\n",
        "\n",
        "outputs = t5_trt_decoder.greedy_search(\n",
        "            input_ids=decoder_input_ids,\n",
        "            encoder_hidden_states=encoder_last_hidden_state,\n",
        "            stopping_criteria = StoppingCriteriaList([MaxLengthCriteria(max_length)])\n",
        "        )\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ],
      "id": "8d71a327-546f-4b5b-bd42-caaffcceafc7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed9d4a98-b034-470e-a9f8-096d4100b8d4"
      },
      "source": [
        "#### TRT engine inference benchmark: encoder and decoder stacks\n",
        "First, we will bechmark the encoder and decoder stacks as before."
      ],
      "id": "ed9d4a98-b034-470e-a9f8-096d4100b8d4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70b37591-4398-40ff-8a39-5f75347192dc"
      },
      "outputs": [],
      "source": [
        "encoder_last_hidden_state, encoder_e2e_median_time = encoder_inference(\n",
        "    t5_trt_encoder, input_ids, TimingProfile(10,1,1)\n",
        ")\n",
        "encoder_e2e_median_time\n"
      ],
      "id": "70b37591-4398-40ff-8a39-5f75347192dc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7e5459da-a01b-4894-88dc-01b3637ded53"
      },
      "outputs": [],
      "source": [
        "_, decoder_e2e_median_time = decoder_inference(\n",
        "    t5_trt_decoder, input_ids, encoder_last_hidden_state, TimingProfile(10,1,1)\n",
        ")\n",
        "decoder_e2e_median_time"
      ],
      "id": "7e5459da-a01b-4894-88dc-01b3637ded53"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62ebfe03-7a60-4dd0-ad32-4e53d6012b07"
      },
      "source": [
        "### Full model inference benchmark\n",
        "\n",
        "Next, we will try the full TensorRT T5 engine for the task of translation. As before, note the time difference."
      ],
      "id": "62ebfe03-7a60-4dd0-ad32-4e53d6012b07"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f31cb550-24b9-48cd-a4ec-0bf18ac5e40c"
      },
      "outputs": [],
      "source": [
        "decoder_output_greedy, full_e2e_median_runtime = full_inference_greedy(\n",
        "    t5_trt_encoder,\n",
        "    t5_trt_decoder,\n",
        "    input_ids,\n",
        "    tokenizer,\n",
        "     TimingProfile(10,1,1),\n",
        "    max_length=T5ModelTRTConfig.MAX_SEQUENCE_LENGTH[metadata.variant],\n",
        "    use_cuda=False,\n",
        ")\n",
        "\n",
        "print(tokenizer.decode(decoder_output_greedy[0], skip_special_tokens=True))\n",
        "full_e2e_median_runtime\n"
      ],
      "id": "f31cb550-24b9-48cd-a4ec-0bf18ac5e40c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92031643-8ee8-4d50-864b-a08e4d551dc6"
      },
      "source": [
        "You can now compare the output of the original PyTorch model and the TensorRT engine. Notice the speed difference. On an NVIDIA V100 32GB GPU, this results in upto ~10x performance improvement (from 0.0802s to 0.0082s for the T5-small variant)."
      ],
      "id": "92031643-8ee8-4d50-864b-a08e4d551dc6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a1f5dca-397c-4c8c-9200-61b30cdba824"
      },
      "source": [
        "## Conclusion and where-to next?\n",
        "\n",
        "This notebook has walked you through the process of converting a HuggingFace PyTorch T5 model to an optimized TensorRT engine for inference in 3 easy steps. The TensorRT inference engine can be conviniently used as a drop-in replacement for the orginial HuggingFace T5 model while providing significant speed up.\n",
        "\n",
        "If you are interested in further details of the conversion process, check out [T5/trt.py](../T5/trt.py)"
      ],
      "id": "2a1f5dca-397c-4c8c-9200-61b30cdba824"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}